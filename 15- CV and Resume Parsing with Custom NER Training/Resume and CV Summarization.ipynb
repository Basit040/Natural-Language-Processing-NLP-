{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede35e2e",
   "metadata": {},
   "source": [
    "# RESUME AND CV SUMMARIZATION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34aa98d0",
   "metadata": {},
   "source": [
    "Example here: https://spacy.io/usage/training#training-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c336d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2c744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pickle.load(open('train_data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d169465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
       " {'entities': [(1749, 1755, 'Companies worked at'),\n",
       "   (1696, 1702, 'Companies worked at'),\n",
       "   (1417, 1423, 'Companies worked at'),\n",
       "   (1356, 1793, 'Skills'),\n",
       "   (1209, 1215, 'Companies worked at'),\n",
       "   (1136, 1248, 'Skills'),\n",
       "   (928, 932, 'Graduation Year'),\n",
       "   (858, 889, 'College Name'),\n",
       "   (821, 856, 'Degree'),\n",
       "   (787, 791, 'Graduation Year'),\n",
       "   (744, 750, 'Companies worked at'),\n",
       "   (722, 742, 'Designation'),\n",
       "   (658, 664, 'Companies worked at'),\n",
       "   (640, 656, 'Designation'),\n",
       "   (574, 580, 'Companies worked at'),\n",
       "   (555, 573, 'Designation'),\n",
       "   (470, 493, 'Companies worked at'),\n",
       "   (444, 469, 'Designation'),\n",
       "   (308, 314, 'Companies worked at'),\n",
       "   (234, 240, 'Companies worked at'),\n",
       "   (175, 198, 'Companies worked at'),\n",
       "   (93, 137, 'Email Address'),\n",
       "   (39, 48, 'Location'),\n",
       "   (13, 38, 'Designation'),\n",
       "   (0, 12, 'Name')]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a59104",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82fc9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.blank('en')\n",
    "def train_model(train_data):\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner= nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "        \n",
    "    for _, annotation in train_data:\n",
    "        for ent in annotation['entities']:\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    other_pipes= [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes): #only train NER\n",
    "        optimizer= nlp.begin_training()\n",
    "        for itn in range(10):\n",
    "            print(\"Starting iteration \"+ str(itn))\n",
    "            random.shuffle(train_data)\n",
    "            losses= {}\n",
    "            index=0\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                #print(index)\n",
    "                try:\n",
    "                    nlp.update(\n",
    "                    [text], # batch of texts\n",
    "                    [annotations], # batch of annotations\n",
    "                    drop=0.2, # dropout\n",
    "                    sgd= optimizer, # callable to update weights\n",
    "                    losses=losses)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "            print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dc425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea2802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b2bc33d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x000001B89D730AC0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ABDULB~1\\AppData\\Local\\Temp/ipykernel_17912/1782899584.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ABDULB~1\\AppData\\Local\\Temp/ipykernel_17912/3639191876.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_data)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'ner'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mner\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotation\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    771\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 773\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x000001B89D730AC0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b33c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train the model\n",
    "train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918aa9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the model for further use\n",
    "nlp.to_disk('nlp_model')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5394d566",
   "metadata": {},
   "source": [
    "Model testing\n",
    "Let's check out how our model is performing. For this we will pass a new resume to this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f87f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing PyMuPDF for getting the text data from the resume pdf\n",
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, fitz\n",
    "\n",
    "fname = '/kaggle/input/resume-data/Alice Clark CV.pdf'\n",
    "doc = fitz.open(fname)\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text = text + str(page.getText())\n",
    "\n",
    "tx = \" \".join(text.split('\\n'))  # for removing the next line character '/n'\n",
    "print(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will pass this extracted text to our model\n",
    "nlp_model = nlp.from_disk('/kaggle/input/resume-data/nlp_model/')\n",
    "\n",
    "doc = nlp_model(tx)\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d514d078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec0007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf44b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a1dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
