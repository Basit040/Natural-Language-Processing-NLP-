{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cfbda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bd1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0e0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"twitter16m.csv\", encoding='latin1', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f77735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbdd293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We concern only sentiment and tweets columns thai is column 0 & 5\n",
    "df= df[[5,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51053169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0\n",
       "1  is upset that he can't update his Facebook by ...          0\n",
       "2  @Kenichan I dived many times for the ball. Man...          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns= ['tweets','sentiment']\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2812d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "4    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e340b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_map= {0: 'negative', 4:'positive'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc3e64",
   "metadata": {},
   "source": [
    "## Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ed0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column for word counts\n",
    "df['word_counts']= df['tweets'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1dd04c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0           19\n",
       "1  is upset that he can't update his Facebook by ...          0           21\n",
       "2  @Kenichan I dived many times for the ball. Man...          0           18\n",
       "3    my whole body feels itchy and like its on fire           0           10\n",
       "4  @nationwideclass no, it's not behaving at all....          0           21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b44c92",
   "metadata": {},
   "source": [
    "## Character Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28051716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column for character counts\n",
    "df['char_counts']= df['tweets'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9a16d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0           19   \n",
       "1  is upset that he can't update his Facebook by ...          0           21   \n",
       "\n",
       "   char_counts  \n",
       "0          115  \n",
       "1          111  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4cfb05",
   "metadata": {},
   "source": [
    "## Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d317616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_word_len(x):\n",
    "    words= x.split()\n",
    "    word_len=0\n",
    "    for word in words:\n",
    "        word_len=word_len + len(word)\n",
    "    return word_len/len(words)  # != len(x)/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "147d1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_word_len']= df['tweets'].apply(lambda x: get_avg_word_len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b88978a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0           19   \n",
       "1  is upset that he can't update his Facebook by ...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  \n",
       "0          115      5.052632  \n",
       "1          111      4.285714  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de029d3",
   "metadata": {},
   "source": [
    "## STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cfb37f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'up', 'three', 'really', 'done', 'becomes', 'thereupon', 'without', 'per', 'but', 'therefore', 'perhaps', 'same', 'were', 'beside', '’ll', 'she', 'often', 'wherein', 'another', 'mine', 'your', 'empty', 'has', 're', 'while', '‘d', 'hence', 'cannot', 'none', 'somehow', 'with', 'third', 'fifty', 'thru', 'least', 'toward', 'always', 'its', 'out', 'go', 'however', 'therein', '’d', 'well', 'give', 'who', 'meanwhile', '‘re', 'already', 'ourselves', 'once', 'someone', 'noone', 'quite', 'just', 'else', 'us', 'which', 'anywhere', 'everywhere', 'have', 'less', 'what', 'afterwards', 'indeed', 'among', 'a', 'become', 'nowhere', 'still', 'five', 'hundred', 'keep', 'my', '’m', 'latterly', 'ever', 'are', 'some', 'doing', 'whereas', 'whom', 'was', 'take', '’s', 'beforehand', 'is', 'twelve', 'wherever', 'amount', \"'ll\", 'four', 'whenever', 'where', 'because', 'elsewhere', 'more', 'make', 'n’t', 'whereupon', 'together', 'anyhow', 'forty', 'an', 'am', 'get', 'whose', 'did', 'will', 'them', 'must', 'many', 'used', 'whole', 'our', 'front', 'sometime', 'top', 'during', 'or', 'across', 'others', '‘m', 'unless', 'also', 'you', 'no', 'moreover', 'than', 'own', 'himself', 'from', 'if', 'they', 'does', 'at', 'off', 'otherwise', 'down', 'either', 'first', 'not', 'this', 'somewhere', 'so', 'over', 'should', 'alone', 'between', 'been', 'that', 'thus', 'yourself', 'formerly', 'each', 'hereupon', 'whither', 'becoming', 'most', 'both', 'why', 'had', 'seems', '‘ve', 'now', 'whatever', 'herself', 'as', 'nothing', 'side', 'the', 'besides', 'when', 'themselves', 'say', 'sixty', '‘ll', 'since', 'might', 'even', 'rather', 'except', 'hers', 'nine', 'too', 'before', 'onto', \"n't\", 'name', 'behind', 'everything', 'every', 'be', 'whereby', 'part', 'all', 'few', 'anyway', 'n‘t', 'anyone', \"'ve\", 'became', 'seeming', 'such', 'whoever', 'above', 'their', 'he', 'although', 'those', 'by', 'myself', 'for', 'in', 'until', 'it', '’ve', 'into', 'next', 'serious', 'please', 'former', 'on', 'though', 'nevertheless', 'show', 'there', 'amongst', \"'re\", 'do', 'against', 'seem', 'hereafter', 'using', 'two', 'call', 'i', 'ten', 'towards', 'here', 'everyone', 'can', 'six', 'nobody', 'last', \"'s\", 'through', 'how', 'his', 'see', 'only', 'whereafter', \"'d\", 'whether', 'further', '’re', 'beyond', 'would', 'yours', 'may', 'him', 'these', 'mostly', 'seemed', 'never', \"'m\", 'and', 'bottom', 'twenty', '‘s', 'enough', 'nor', 'of', 'within', 'made', 'thence', 'move', 'could', 'several', 'around', 'ours', 'thereafter', 'latter', 'almost', 'hereby', 'again', 'then', 'neither', 'below', 'due', 'yet', 'one', 'much', 'via', 'itself', 'regarding', 'put', 'eight', 'thereby', 'me', 'full', 'yourselves', 'along', 'something', 'under', 'to', 'whence', 'namely', 'very', 'various', 'back', 'anything', 'we', 'about', 'being', 'after', 'ca', 'her', 'any', 'throughout', 'other', 'sometimes', 'fifteen', 'upon', 'eleven', 'herein'}\n"
     ]
    }
   ],
   "source": [
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64d8e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for understanding the next code that how many stop words included in tweets\n",
    "x= \"this is text data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f400894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'text', 'data']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92805330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in x.split() if t in STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b43bb875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([t for t in x.split() if t in STOP_WORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f4db142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stop_words_len']=df['tweets'].apply(lambda x: len([t for t in x.split() if t in STOP_WORDS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e1fbeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0           19   \n",
       "1  is upset that he can't update his Facebook by ...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  \n",
       "0          115      5.052632               4  \n",
       "1          111      4.285714               9  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46363167",
   "metadata": {},
   "source": [
    "## Count #Hashtags and @Mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3446418",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= \"This #hashtag and this is @mention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efd5ca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#hashtag']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in x.split() if t.startswith('#')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8788eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hashtags_counts']= df['tweets'].apply(lambda x: len([t for t in x.split() if t.startswith('#')]))\n",
    "df['mentions_counts']= df['tweets'].apply(lambda x: len([t for t in x.split() if t.startswith('@')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "704fd323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0           19   \n",
       "1  is upset that he can't update his Facebook by ...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  mentions_counts  \n",
       "0          115      5.052632               4                0                1  \n",
       "1          111      4.285714               9                0                0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94299359",
   "metadata": {},
   "source": [
    "## If Numeric digits are present in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c16e2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numerics_count']=df['tweets'].apply(lambda x: len([t for t in x.split() if t.isdigit()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5517a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0           19   \n",
       "1  is upset that he can't update his Facebook by ...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "\n",
       "   mentions_counts  numerics_count  \n",
       "0                1               0  \n",
       "1                0               0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156df67",
   "metadata": {},
   "source": [
    "## Upper Case Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50d563ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['upper_counts']= df['tweets'].apply(lambda x: len([t for t in x.split() if t.isupper() and len(x)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d86c378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0           19   \n",
       "1  is upset that he can't update his Facebook by ...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "\n",
       "   mentions_counts  numerics_count  upper_counts  \n",
       "0                1               0             1  \n",
       "1                0               0             0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25e91704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"so rylee,grace...wana go steve's party or not?? SADLY SINCE ITS EASTER I WNT B ABLE 2 DO MUCH  BUT OHH WELL.....\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[96]['tweets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9515a",
   "metadata": {},
   "source": [
    "## Preprocessing and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc0805d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets']= df['tweets'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0412461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - awww, t...          0           19   \n",
       "1  is upset that he can't update his facebook by ...          0           21   \n",
       "2  @kenichan i dived many times for the ball. man...          0           18   \n",
       "3    my whole body feels itchy and like its on fire           0           10   \n",
       "4  @nationwideclass no, it's not behaving at all....          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "2           89      3.944444               7                0   \n",
       "3           47      3.700000               5                0   \n",
       "4          111      4.285714              10                0   \n",
       "\n",
       "   mentions_counts  numerics_count  upper_counts  \n",
       "0                1               0             1  \n",
       "1                0               0             0  \n",
       "2                1               0             1  \n",
       "3                0               0             0  \n",
       "4                1               0             1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea1ce71",
   "metadata": {},
   "source": [
    "## Contraction To Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86b4a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't to do not , i n u, I and You ,etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d77384f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# For contraction, there is a library, we can use this code\\n# import library\\nimport contractions\\n# contracted text\\ntext = 'I'll be there within 5 min. Shouldn't you be there too?\\nI'd love to see u there my dear. It's awesome to meet new friends.\\nWe've been waiting for this day for so long.'\\n\\n# creating an empty list\\nexpanded_words = []\\nfor word in text.split():\\n# using contractions.fix to expand the shortened words\\nexpanded_words.append(contractions.fix(word))\\n\\nexpanded_text = ' '.join(expanded_words)\\nprint('Original text: ' + text)\\nprint('Expanded_text: ' + expanded_text)\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# For contraction, there is a library, we can use this code\n",
    "# import library\n",
    "import contractions\n",
    "# contracted text\n",
    "text = 'I'll be there within 5 min. Shouldn't you be there too?\n",
    "I'd love to see u there my dear. It's awesome to meet new friends.\n",
    "We've been waiting for this day for so long.'\n",
    "\n",
    "# creating an empty list\n",
    "expanded_words = []\n",
    "for word in text.split():\n",
    "# using contractions.fix to expand the shortened words\n",
    "expanded_words.append(contractions.fix(word))\n",
    "\n",
    "expanded_text = ' '.join(expanded_words)\n",
    "print('Original text: ' + text)\n",
    "print('Expanded_text: ' + expanded_text)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4dc1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions= {\n",
    "  \"ain't\": \"am not\",\n",
    "  \"aren't\": \"are not\",\n",
    "  \"can't\": \"cannot\",\n",
    "  \"can't've\": \"cannot have\",\n",
    "  \"'cause\": \"because\",\n",
    "  \"could've\": \"could have\",\n",
    "  \"couldn't\": \"could not\",\n",
    "  \"couldn't've\": \"could not have\",\n",
    "  \"didn't\": \"did not\",\n",
    "  \"doesn't\": \"does not\",\n",
    "  \"don't\": \"do not\",\n",
    "  \"hadn't\": \"had not\",\n",
    "  \"hadn't've\": \"had not have\",\n",
    "  \"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\n",
    "  \"he'd\": \"he would\",\n",
    "  \"he'd've\": \"he would have\",\n",
    "  \"he'll\": \"he will\",\n",
    "  \"he'll've\": \"he will have\",\n",
    "  \"he's\": \"he is\",\n",
    "  \"how'd\": \"how did\",\n",
    "  \"how'd'y\": \"how do you\",\n",
    "  \"how'll\": \"how will\",\n",
    "  \"how's\": \"how is\",\n",
    "  \"i'd\": \"i would\",\n",
    "  \"i'd've\": \"i would have\",\n",
    "  \"i'll\": \"i will\",\n",
    "  \"i'll've\": \"i will have\",\n",
    "  \"i'm\": \"i am\",\n",
    "  \"i've\": \"i have\",\n",
    "  \"isn't\": \"is not\",\n",
    "  \"it'd\": \"it had\",\n",
    "  \"it'd've\": \"it would have\",\n",
    "  \"it'll\": \"it will\",\n",
    "  \"it'll've\": \"it will have\",\n",
    "  \"it's\": \"it is\",\n",
    "  \"let's\": \"let us\",\n",
    "  \"ma'am\": \"madam\",\n",
    "  \"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\n",
    "  \"mightn't\": \"might not\",\n",
    "  \"mightn't've\": \"might not have\",\n",
    "  \"must've\": \"must have\",\n",
    "  \"mustn't\": \"must not\",\n",
    "  \"mustn't've\": \"must not have\",\n",
    "  \"needn't\": \"need not\",\n",
    "  \"needn't've\": \"need not have\",\n",
    "  \"o'clock\": \"of the clock\",\n",
    "  \"oughtn't\": \"ought not\",\n",
    "  \"oughtn't've\": \"ought not have\",\n",
    "  \"shan't\": \"shall not\",\n",
    "  \"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\n",
    "  \"she'd\": \"she would\",\n",
    "  \"she'd've\": \"she would have\",\n",
    "  \"she'll\": \"she will\",\n",
    "  \"she'll've\": \"she will have\",\n",
    "  \"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\n",
    "  \"shouldn't\": \"should not\",\n",
    "  \"shouldn't've\": \"should not have\",\n",
    "  \"so've\": \"so have\",\n",
    "  \"so's\": \"so is\",\n",
    "  \"that'd\": \"that would\",\n",
    "  \"that'd've\": \"that would have\",\n",
    "  \"that's\": \"that is\",\n",
    "  \"there'd\": \"there had\",\n",
    "  \"there'd've\": \"there would have\",\n",
    "  \"there's\": \"there is\",\n",
    "  \"they'd\": \"they would\",\n",
    "  \"they'd've\": \"they would have\",\n",
    "  \"they'll\": \"they will\",\n",
    "  \"they'll've\": \"they will have\",\n",
    "  \"they're\": \"they are\",\n",
    "  \"they've\": \"they have\",\n",
    "  \"to've\": \"to have\",\n",
    "  \"wasn't\": \"was not\",\n",
    "  \"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\n",
    "  \"we'll\": \"we will\",\n",
    "  \"we'll've\": \"we will have\",\n",
    "  \"we're\": \"we are\",\n",
    "  \"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\n",
    "  \"what'll\": \"what will\",\n",
    "  \"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"what's\": \"what is\",\n",
    "  \"what've\": \"what have\",\n",
    "  \"when's\": \"when is\",\n",
    "  \"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\n",
    "  \"where's\": \"where is\",\n",
    "  \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"who's\": \"who is\",\n",
    "  \"who've\": \"who have\",\n",
    "  \"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"won't\": \"will not\",\n",
    "  \"won't've\": \"will not have\",\n",
    "  \"would've\": \"would have\",\n",
    "  \"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\n",
    "  \"y'all\": \"you all\",\n",
    "  \"y'alls\": \"you alls\",\n",
    "  \"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\n",
    "  \"y'all're\": \"you all are\",\n",
    "  \"y'all've\": \"you all have\",\n",
    "  \"you'd\": \"you had\",\n",
    "  \"you'd've\": \"you would have\",\n",
    "  \"you'll\": \"you you will\",\n",
    "  \"you'll've\": \"you you will have\",\n",
    "  \"you're\": \"you are\",\n",
    "  \"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b6423aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        for key in contractions:\n",
    "            value= contractions[key]\n",
    "            x=x.replace(key,value)\n",
    "        return x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "875bb474",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= \"hi, i'd be happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dd574d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi, i would be happy'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_to_exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49213278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['tweets']= df['tweets'].apply(lambda x: cont_to_exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d60ae8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - awww, t...          0           19   \n",
       "1  is upset that he cannot update his facebook by...          0           21   \n",
       "2  @kenichan i dived many times for the ball. man...          0           18   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "2           89      3.944444               7                0   \n",
       "\n",
       "   mentions_counts  numerics_count  upper_counts  \n",
       "0                1               0             1  \n",
       "1                0               0             0  \n",
       "2                1               0             1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aeadb5",
   "metadata": {},
   "source": [
    "## Count and Remove emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83a5f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8d382a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'hi my email is abdulbasit@yahoo.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9142819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdulbasit@yahoo.com']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a62f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emails']=df['tweets'].apply(lambda x: re.findall(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90170727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emails_count']=df['emails'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "701f542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "      <th>emails</th>\n",
       "      <th>emails_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>i want a new laptop.  hp tx2000 is the bomb. :...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>103</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[gabbehhramos@yahoo.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>who stole elledell@gmail.com?</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[elledell@gmail.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>@alexistehpom  really? did you send out all th...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[missataari@gmail.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10290</th>\n",
       "      <td>@laureystack awh...that is kinda sad  lol add ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hello.kitty.65@hotmail.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16413</th>\n",
       "      <td>@jilliancyork  got 2 bottom of it, human error...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>137</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[press@linkedin.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588338</th>\n",
       "      <td>@boudoirsextoys do not forget to shoot me an e...</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>127</td>\n",
       "      <td>5.047619</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[hello@tastelikekisses.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589132</th>\n",
       "      <td>hi there , anybody got a job for me  oil &amp;amp;...</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>98</td>\n",
       "      <td>5.533333</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[aadvanspijk@yahoo.co.uk]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590489</th>\n",
       "      <td>@clericaaron yes, lbruton@tulsalanparty.com is...</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>95</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[lbruton@tulsalanparty.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591675</th>\n",
       "      <td>@miss_ellen good morning!!!!   congrats!    se...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>7.111111</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[jill@q985fm.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599053</th>\n",
       "      <td>@thejoshlynn you are! btw send me an email. wa...</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>145</td>\n",
       "      <td>6.631579</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[marni@creativecustomcardboxes.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweets  sentiment  \\\n",
       "4054     i want a new laptop.  hp tx2000 is the bomb. :...          0   \n",
       "7917                       who stole elledell@gmail.com?            0   \n",
       "8496     @alexistehpom  really? did you send out all th...          0   \n",
       "10290    @laureystack awh...that is kinda sad  lol add ...          0   \n",
       "16413    @jilliancyork  got 2 bottom of it, human error...          0   \n",
       "...                                                    ...        ...   \n",
       "1588338  @boudoirsextoys do not forget to shoot me an e...          4   \n",
       "1589132  hi there , anybody got a job for me  oil &amp;...          4   \n",
       "1590489  @clericaaron yes, lbruton@tulsalanparty.com is...          4   \n",
       "1591675  @miss_ellen good morning!!!!   congrats!    se...          4   \n",
       "1599053  @thejoshlynn you are! btw send me an email. wa...          4   \n",
       "\n",
       "         word_counts  char_counts  avg_word_len  stop_words_len  \\\n",
       "4054              20          103      4.150000               6   \n",
       "7917               3           31      9.000000               1   \n",
       "8496              20          130      5.500000              11   \n",
       "10290              8           76      8.500000               0   \n",
       "16413             21          137      5.428571               7   \n",
       "...              ...          ...           ...             ...   \n",
       "1588338           21          127      5.047619              10   \n",
       "1589132           15           98      5.533333               4   \n",
       "1590489           14           95      5.785714               6   \n",
       "1591675            9           77      7.111111               2   \n",
       "1599053           19          145      6.631579               7   \n",
       "\n",
       "         hashtags_counts  mentions_counts  numerics_count  upper_counts  \\\n",
       "4054                   0                0               0             4   \n",
       "7917                   0                0               0             0   \n",
       "8496                   0                1               0             0   \n",
       "10290                  0                1               0             0   \n",
       "16413                  0                1               1             0   \n",
       "...                  ...              ...             ...           ...   \n",
       "1588338                0                1               0             1   \n",
       "1589132                0                0               0             0   \n",
       "1590489                0                1               0             1   \n",
       "1591675                0                1               0             0   \n",
       "1599053                0                1               0             1   \n",
       "\n",
       "                                      emails  emails_count  \n",
       "4054                [gabbehhramos@yahoo.com]             1  \n",
       "7917                    [elledell@gmail.com]             1  \n",
       "8496                  [missataari@gmail.com]             1  \n",
       "10290           [hello.kitty.65@hotmail.com]             1  \n",
       "16413                   [press@linkedin.com]             1  \n",
       "...                                      ...           ...  \n",
       "1588338          [hello@tastelikekisses.com]             1  \n",
       "1589132            [aadvanspijk@yahoo.co.uk]             1  \n",
       "1590489          [lbruton@tulsalanparty.com]             1  \n",
       "1591675                    [jill@q985fm.com]             1  \n",
       "1599053  [marni@creativecustomcardboxes.com]             1  \n",
       "\n",
       "[564 rows x 12 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['emails_count']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "469a5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove email from tweets\n",
    "df['tweets']=df['tweets'].apply(lambda x: re.sub(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c75e193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "      <th>emails</th>\n",
       "      <th>emails_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it is not behaving at all...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - awww, t...          0           19   \n",
       "1  is upset that he cannot update his facebook by...          0           21   \n",
       "2  @kenichan i dived many times for the ball. man...          0           18   \n",
       "3    my whole body feels itchy and like its on fire           0           10   \n",
       "4  @nationwideclass no, it is not behaving at all...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "2           89      3.944444               7                0   \n",
       "3           47      3.700000               5                0   \n",
       "4          111      4.285714              10                0   \n",
       "\n",
       "   mentions_counts  numerics_count  upper_counts emails  emails_count  \n",
       "0                1               0             1     []             0  \n",
       "1                0               0             0     []             0  \n",
       "2                1               0             1     []             0  \n",
       "3                0               0             0     []             0  \n",
       "4                1               0             1     []             0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "131c882d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "      <th>emails</th>\n",
       "      <th>emails_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>i want a new laptop.  hp tx2000 is the bomb. :...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>103</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[gabbehhramos@yahoo.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>who stole ?</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[elledell@gmail.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>@alexistehpom  really? did you send out all th...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>130</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[missataari@gmail.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10290</th>\n",
       "      <td>@laureystack awh...that is kinda sad  lol add ...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>76</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hello.kitty.65@hotmail.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16413</th>\n",
       "      <td>@jilliancyork  got 2 bottom of it, human error...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>137</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[press@linkedin.com]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets  sentiment  \\\n",
       "4054   i want a new laptop.  hp tx2000 is the bomb. :...          0   \n",
       "7917                                       who stole ?            0   \n",
       "8496   @alexistehpom  really? did you send out all th...          0   \n",
       "10290  @laureystack awh...that is kinda sad  lol add ...          0   \n",
       "16413  @jilliancyork  got 2 bottom of it, human error...          0   \n",
       "\n",
       "       word_counts  char_counts  avg_word_len  stop_words_len  \\\n",
       "4054            20          103      4.150000               6   \n",
       "7917             3           31      9.000000               1   \n",
       "8496            20          130      5.500000              11   \n",
       "10290            8           76      8.500000               0   \n",
       "16413           21          137      5.428571               7   \n",
       "\n",
       "       hashtags_counts  mentions_counts  numerics_count  upper_counts  \\\n",
       "4054                 0                0               0             4   \n",
       "7917                 0                0               0             0   \n",
       "8496                 0                1               0             0   \n",
       "10290                0                1               0             0   \n",
       "16413                0                1               1             0   \n",
       "\n",
       "                             emails  emails_count  \n",
       "4054       [gabbehhramos@yahoo.com]             1  \n",
       "7917           [elledell@gmail.com]             1  \n",
       "8496         [missataari@gmail.com]             1  \n",
       "10290  [hello.kitty.65@hotmail.com]             1  \n",
       "16413          [press@linkedin.com]             1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['emails_count']>0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d046e",
   "metadata": {},
   "source": [
    "## Count URLs and Remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6bffaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'hi, to watch more visit https://youtube.com/gshjskbsk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff7b8b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https', 'youtube.com', '/gshjskbsk')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ac46bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of urls in each tweet\n",
    "df['urls_flag']= df['tweets'].apply(lambda x: len(re.findall(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37088da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi, to watch more visit '"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing on our x\n",
    "re.sub(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?','',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86f041df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now on tweets to remove urls\n",
    "df['tweets']= df['tweets'].apply(lambda x: re.sub(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c473f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "      <th>emails</th>\n",
       "      <th>emails_count</th>\n",
       "      <th>urls_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot  - awww, that is a bummer.  you sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it is not behaving at all...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot  - awww, that is a bummer.  you sh...          0           19   \n",
       "1  is upset that he cannot update his facebook by...          0           21   \n",
       "2  @kenichan i dived many times for the ball. man...          0           18   \n",
       "3    my whole body feels itchy and like its on fire           0           10   \n",
       "4  @nationwideclass no, it is not behaving at all...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "2           89      3.944444               7                0   \n",
       "3           47      3.700000               5                0   \n",
       "4          111      4.285714              10                0   \n",
       "\n",
       "   mentions_counts  numerics_count  upper_counts emails  emails_count  \\\n",
       "0                1               0             1     []             0   \n",
       "1                0               0             0     []             0   \n",
       "2                1               0             1     []             0   \n",
       "3                0               0             0     []             0   \n",
       "4                1               0             1     []             0   \n",
       "\n",
       "   urls_flag  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf30f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@switchfoot  - awww, that is a bummer.  you shoulda got david carr of third day to do it. ;d'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0]['tweets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c8c0f7",
   "metadata": {},
   "source": [
    "## Remove RT (Re Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa327b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets']=df['tweets'].apply(lambda x: re.sub('RT', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fcb7292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "      <th>emails</th>\n",
       "      <th>emails_count</th>\n",
       "      <th>urls_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot  - awww, that is a bummer.  you sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it is not behaving at all...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  @switchfoot  - awww, that is a bummer.  you sh...          0           19   \n",
       "1  is upset that he cannot update his facebook by...          0           21   \n",
       "2  @kenichan i dived many times for the ball. man...          0           18   \n",
       "3    my whole body feels itchy and like its on fire           0           10   \n",
       "4  @nationwideclass no, it is not behaving at all...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "2           89      3.944444               7                0   \n",
       "3           47      3.700000               5                0   \n",
       "4          111      4.285714              10                0   \n",
       "\n",
       "   mentions_counts  numerics_count  upper_counts emails  emails_count  \\\n",
       "0                1               0             1     []             0   \n",
       "1                0               0             0     []             0   \n",
       "2                1               0             1     []             0   \n",
       "3                0               0             0     []             0   \n",
       "4                1               0             1     []             0   \n",
       "\n",
       "   urls_flag  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f227d780",
   "metadata": {},
   "source": [
    "## Special Characters removal or Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de8e66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets']=df['tweets'].apply(lambda x: re.sub('[^A-Z a-z 0-9-]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd68ffd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "      <th>emails</th>\n",
       "      <th>emails_count</th>\n",
       "      <th>urls_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>switchfoot  - awww that is a bummer  you shoul...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kenichan i dived many times for the ball manag...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nationwideclass no it is not behaving at all i...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  switchfoot  - awww that is a bummer  you shoul...          0           19   \n",
       "1  is upset that he cannot update his facebook by...          0           21   \n",
       "2  kenichan i dived many times for the ball manag...          0           18   \n",
       "3    my whole body feels itchy and like its on fire           0           10   \n",
       "4  nationwideclass no it is not behaving at all i...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "2           89      3.944444               7                0   \n",
       "3           47      3.700000               5                0   \n",
       "4          111      4.285714              10                0   \n",
       "\n",
       "   mentions_counts  numerics_count  upper_counts emails  emails_count  \\\n",
       "0                1               0             1     []             0   \n",
       "1                0               0             0     []             0   \n",
       "2                1               0             1     []             0   \n",
       "3                0               0             0     []             0   \n",
       "4                1               0             1     []             0   \n",
       "\n",
       "   urls_flag  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b10e58",
   "metadata": {},
   "source": [
    "## Remove Multiple Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b68de5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'Thanks for   watching   video'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4155088b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks for watching video'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d79f18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets']=df['tweets'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d0a8724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "      <th>emails</th>\n",
       "      <th>emails_count</th>\n",
       "      <th>urls_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>switchfoot - awww that is a bummer you shoulda...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  switchfoot - awww that is a bummer you shoulda...          0           19   \n",
       "1  is upset that he cannot update his facebook by...          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "\n",
       "   mentions_counts  numerics_count  upper_counts emails  emails_count  \\\n",
       "0                1               0             1     []             0   \n",
       "1                0               0             0     []             0   \n",
       "\n",
       "   urls_flag  \n",
       "0          1  \n",
       "1          0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31f197",
   "metadata": {},
   "source": [
    "## Remove HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f3b81939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7423550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x='<html><h2>Thanks for watching</h2></html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb18460f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks for watching'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(x,'lxml').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f810c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['tweets']=df['tweets'].apply(lambda x: BeautifulSoup(x,'lxml').get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f5ce1",
   "metadata": {},
   "source": [
    "## Remove Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33b2d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "297eeea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'èaccent grave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "00a521b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(x):\n",
    "    x= unicodedata.normalize(\"NFKD\",x).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51c91b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eaccent grave'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_accented_chars(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "80abaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets']=df['tweets'].apply(lambda x: remove_accented_chars(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72535897",
   "metadata": {},
   "source": [
    "# SPACY and NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f0492",
   "metadata": {},
   "source": [
    "## Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3fb471ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f6079711",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'this is stop words removal code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c4ef4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stop words removal code'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([t for t in x.split() if t not in STOP_WORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "07dd16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweets']=df['tweets'].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db6a69b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>stop_words_len</th>\n",
       "      <th>hashtags_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>numerics_count</th>\n",
       "      <th>upper_counts</th>\n",
       "      <th>emails</th>\n",
       "      <th>emails_count</th>\n",
       "      <th>urls_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>switchfoot - awww bummer shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>115</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upset update facebook texting cry result schoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kenichan dived times ball managed save 50 rest...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>3.944444</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>body feels itchy like fire</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nationwideclass behaving mad</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>111</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sentiment  word_counts  \\\n",
       "0  switchfoot - awww bummer shoulda got david car...          0           19   \n",
       "1  upset update facebook texting cry result schoo...          0           21   \n",
       "2  kenichan dived times ball managed save 50 rest...          0           18   \n",
       "3                         body feels itchy like fire          0           10   \n",
       "4                       nationwideclass behaving mad          0           21   \n",
       "\n",
       "   char_counts  avg_word_len  stop_words_len  hashtags_counts  \\\n",
       "0          115      5.052632               4                0   \n",
       "1          111      4.285714               9                0   \n",
       "2           89      3.944444               7                0   \n",
       "3           47      3.700000               5                0   \n",
       "4          111      4.285714              10                0   \n",
       "\n",
       "   mentions_counts  numerics_count  upper_counts emails  emails_count  \\\n",
       "0                1               0             1     []             0   \n",
       "1                0               0             0     []             0   \n",
       "2                1               0             1     []             0   \n",
       "3                0               0             0     []             0   \n",
       "4                1               0             1     []             0   \n",
       "\n",
       "   urls_flag  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8073cc7",
   "metadata": {},
   "source": [
    "## Convert into base or root form of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9614975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b06d4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'kenichan dived times ball managed save 50 rest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "180b28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dive= dived, time= times, manage= managed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d82b29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x= 'i you he she they is am are'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2954d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_to_base(x):\n",
    "    x_list=[]\n",
    "    doc=nlp(x)\n",
    "    \n",
    "    for token in doc:\n",
    "        lemma= str(token.lemma_)\n",
    "        if lemma =='-PRON-' or lemma =='be':\n",
    "            lemma= token.text\n",
    "        x_list.append(lemma)\n",
    "    print(\" \".join(x_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f9f7c133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kenichan dive time ball manage save 50 rest\n"
     ]
    }
   ],
   "source": [
    "make_to_base(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd073fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can apply this approach to tweets but i will take hours, we are not doing right now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a000a2",
   "metadata": {},
   "source": [
    "## Common Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "78ef8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are joing all data (onlly head) of tweets in text form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e64e705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'switchfoot - awww bummer shoulda got david carr day d upset update facebook texting cry result school today blah kenichan dived times ball managed save 50 rest bounds body feels itchy like fire nationwideclass behaving mad'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(df.head()['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "784f554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now joining all tweets in text\n",
    "text= \" \".join(df['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ed147bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3c38559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extracting frequency of each words\n",
    "freq_comm= pd.Series(text).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "544b615d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good               89366\n",
       "day                82299\n",
       "like               77735\n",
       "-                  69662\n",
       "today              64512\n",
       "                   ...  \n",
       "kittu                  1\n",
       "cryyyyyyyyyyyyy        1\n",
       "newreporter            1\n",
       "daygta                 1\n",
       "speakinguph4h          1\n",
       "Length: 787042, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "090552a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First top 20 occuring words\n",
    "f20=freq_comm[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a40de0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will remove top 20 occuring words\n",
    "df['tweets']=df['tweets'].apply(lambda x: \" \".join([t for t in x.split() if t not in f20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6626b",
   "metadata": {},
   "source": [
    "## Rare Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4f37ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare20= freq_comm[-20:] #20 words having least frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "50121132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "andychandleruk           1\n",
       "junealeesia              1\n",
       "fanwalk                  1\n",
       "5859                     1\n",
       "colesaw                  1\n",
       "seattleweekly            1\n",
       "optusquot                1\n",
       "easthampton              1\n",
       "uhohhippos               1\n",
       "tayastorm                1\n",
       "zombiecaptnhook          1\n",
       "anti-rheumatic           1\n",
       "quotinfo-mercialsquot    1\n",
       "movistar                 1\n",
       "mizzdmartin              1\n",
       "kittu                    1\n",
       "cryyyyyyyyyyyyy          1\n",
       "newreporter              1\n",
       "daygta                   1\n",
       "speakinguph4h            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5a608fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare= freq_comm[freq_comm.values==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5bc96974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jennciv            1\n",
       "darrinuser         1\n",
       "clamatis           1\n",
       "cacos              1\n",
       "monthsyup          1\n",
       "                  ..\n",
       "kittu              1\n",
       "cryyyyyyyyyyyyy    1\n",
       "newreporter        1\n",
       "daygta             1\n",
       "speakinguph4h      1\n",
       "Length: 535890, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "724f4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 535890 least frequency (1) words, we will not processed them, it will take huge time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a8fbc6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will remove top 20 least occuring words\n",
    "df['tweets']=df['tweets'].apply(lambda x: \" \".join([t for t in x.split() if t not in rare20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133298f",
   "metadata": {},
   "source": [
    "## WORLD CLOUD VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "12e378b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1.tar.gz (220 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\abdul basit\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\abdul basit\\anaconda3\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abdul basit\\anaconda3\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\abdul basit\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\abdul basit\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abdul basit\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abdul basit\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\abdul basit\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (setup.py): started\n",
      "  Building wheel for wordcloud (setup.py): finished with status 'done'\n",
      "  Created wheel for wordcloud: filename=wordcloud-1.8.1-cp39-cp39-win_amd64.whl size=161062 sha256=d75b38ed1f2807aaf0845350efa2d377543f72fe0440b1ed3fdcf9ab4a1ca9bc\n",
      "  Stored in directory: c:\\users\\abdul basit\\appdata\\local\\pip\\cache\\wheels\\f9\\7a\\dd\\06ef8b5dfe5483f6204133c08eeb16c287cc2c05e290ae2fc0\n",
      "Successfully built wordcloud\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8354b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ad11f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take 20000 words\n",
    "x=' '.join(text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e5985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "550aefcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10853591"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d43308",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WordCloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ABDULB~1\\AppData\\Local\\Temp/ipykernel_5524/2331246488.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'WordCloud' is not defined"
     ]
    }
   ],
   "source": [
    "wc= WordCloud(width=800, height=400).generate(x)\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d03105",
   "metadata": {},
   "source": [
    "## Spelling Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ab591",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e29af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf0734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'thank forr waching this vidio carri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= TextBlob(x).correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c358eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3844ce6",
   "metadata": {},
   "source": [
    "## TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'thanks4watching this video. please like it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251023ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob(x).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad12a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(x)\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c0522",
   "metadata": {},
   "source": [
    "## LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b32112",
   "metadata": {},
   "outputs": [],
   "source": [
    "x='runs run running ran'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30885b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deaa13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in x.split():\n",
    "    print(Word(token).lemmatize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(x)\n",
    "for token in doc:\n",
    "    print(token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529840e",
   "metadata": {},
   "source": [
    "## Detect Entities using NER of Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "x='Breaking News: Donald Trump, the president of the USA is looking to sign a deal to mine the moon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(x)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text + ' - ' + ent.label_ + ' - ' + str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac6aca0",
   "metadata": {},
   "source": [
    "## Detecting Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60acce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964067f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for noun in doc.noun_chunks:\n",
    "    print(noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab81e55",
   "metadata": {},
   "source": [
    "## Translation and Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfac18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Language Code: https://www.loc.gov/standards/iso639-2/php/code_list.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0377ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb= TextBlob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d868d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change in to Arabic\n",
    "tb.translate(to='ar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc99c87",
   "metadata": {},
   "source": [
    "## Use Inbuilt Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec9b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'we all stands together to fight with corona virus. we will win together'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c387f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb= TextBlob(x, analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'we all are suffering from corona'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807480b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb= TextBlob(x, analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34922142",
   "metadata": {},
   "source": [
    "# Advanced Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af0688",
   "metadata": {},
   "source": [
    "## N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ab2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'thanks for watching'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd4bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb= TextBlob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efe96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.ngrams(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca56bba",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8644ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= ['this is first sentence', 'this is second','this is last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1231b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577266a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv= CountVectorizer(ngram_range=(1,1))\n",
    "text_counts= cv.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7577d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a043f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow= pd.DataFrame(text_counts.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d933366",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c298df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fda97",
   "metadata": {},
   "source": [
    "## Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ecc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf= bow.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831619f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in enumerate(tf.itterows()):\n",
    "    for col in row[1].index:\n",
    "        tf.loc[index,col]=tf.loc[index, col]/sum(row[1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016709c",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f650e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1677ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df= pd.DataFrame(x, columns=['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20354c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a3075",
   "metadata": {},
   "outputs": [],
   "source": [
    "N= bow.shape[0]\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb= bow.astype('bool')\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a941ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb['is'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386acd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= bb.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e36bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz= []\n",
    "for col in cols:\n",
    "    nz.append(bb[col].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678109c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf= []\n",
    "for index, col in enumerate(cols):\n",
    "    idf.append(np.log((N+1)/(nz[index]+1))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf9fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20827f80",
   "metadata": {},
   "source": [
    "## TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a96c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a608444",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "x_tfidf= tfidf.fit_transform(x_df['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d138bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d471c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2079abbb",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f0ae1",
   "metadata": {},
   "source": [
    "## Spacy Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c078668",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp('thank you! dog cat lion dfasss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53621d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.has_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "token.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237928a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp('cat').vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb28a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token1 in doc:http://localhost:8888/notebooks/Documents/NLP%20from%20Youtube/13-%20Complete%20Text%20Processing/Complete-Text-processing.ipynb#Word-Embedding\n",
    "    for token2 in doc:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c8146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35d94a7f",
   "metadata": {},
   "source": [
    "# Machine Learning Models for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only 2000 data\n",
    "df0=df[df['sentiment']==0].sample(2000)\n",
    "df4=df[df['sentiment']==4].sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinig them\n",
    "dfr= df0.append(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6337fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70539ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping tweets, sentiment and emails columns\n",
    "dfr_feat= dfr.drop(labels=['tweets','sentiment','emails'],axis=1).reset_index(dop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c41b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= dfr['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d65139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv= CountVectorizer()\n",
    "text_counts= cv.fit_transform(dfr['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_counts.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_bow= pd.DataFrame(text_counts.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae11ff0",
   "metadata": {},
   "source": [
    "# ML ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb79155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afe79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd= SGDClassifier(n_jobs=-1, random_state=42, max_iter=200)\n",
    "lgr= LogisticRegression(random_state=42, max_iter=200)\n",
    "lgrcv= LogisticRegressionCV(cv=2, random_state=42, max_iter=1000)\n",
    "svm= LinearSVC(random_state=42, max_iter=200)\n",
    "rfc= RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= {'SGD':sgd,'LGR':lgr,'LGR-CV':lgrcv,'SVM':svm, 'RFC':rfc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X,y):\n",
    "    scaler= MinMaxScaler(feature_range=(0,1))\n",
    "    X=scaler.fir_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    for key in clf.keys():\n",
    "        clf[key].fit(X_train, y_train)\n",
    "        y_pred = clf[key].predict(X_test)\n",
    "        ac= accuracy_score(y_test, y_pred)\n",
    "        print(key, \" ---->\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "classify(dfr_bow, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9717c5a",
   "metadata": {},
   "source": [
    "## Manual Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05982bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_feat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be601b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "classify(dfr_feat,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3548a757",
   "metadata": {},
   "source": [
    "## Manual + BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a22fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= dfr_feat.join(dfr_bow)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "classify(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4922a",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42357f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf= TfidfVectorizer()\n",
    "X= tfidf.fit_transform(dfr['tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2460a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "classify(pd.DataFrame(X.toarray()),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9153f6a9",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce95b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec(x):\n",
    "    doc= nlp(x)\n",
    "    return doc.vector.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfr['vec']= dfr['tweets'].apply(lambda x: get_vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c591484",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.concatenate(dfr['vec'].to_numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf9bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadfbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(pd.DataFrame(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def predict_w2v(x):\n",
    "    for key in clf.keys():\n",
    "        y_pred= clf[key].predict(get_vec(x))\n",
    "        print(key, \"--->\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43dd18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_w2v(\"Hi, thanks for watching this video. please like and subscribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be118ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_w2v(\"please let me know if you want more videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec1cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
